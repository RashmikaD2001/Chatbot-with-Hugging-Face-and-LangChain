{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T07:16:12.722745Z",
     "start_time": "2025-02-15T07:15:25.966691Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RASHMIKA\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 12:58:05 - Loaded .env file\n"
     ]
    }
   ],
   "source": [
    "import huggingface_hub\n",
    "import transformers\n",
    "import langchain\n",
    "import chainlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce8a3b9041520906",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T07:20:50.682778Z",
     "start_time": "2025-02-15T07:20:49.044719Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import chainlit as cl\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31f14bd9007cc048",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "  # Load .env variables\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = HUGGINGFACEHUB_API_TOKEN\n",
    "\n",
    "conv_model = HuggingFaceHub(\n",
    "    repo_id=\"gpt2-medium\",\n",
    "    model_kwargs={\"temperature\": 0.8, \"max_new_tokens\": 200}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cae128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a helpful AI assistant that makes stories by completing the query provided by the user {query}\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = template,\n",
    "    input_variable = ['query']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfbe89a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RASHMIKA\\AppData\\Local\\Temp\\ipykernel_17576\\3882678295.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  conv_chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "conv_chain = LLMChain(\n",
    "    llm = conv_model,\n",
    "    prompt = prompt,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16a5d1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a helpful AI assistant that makes stories by completing the query provided by the user Once a upon time in Sri Lanka\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RASHMIKA\\AppData\\Roaming\\Python\\Python313\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "You are a helpful AI assistant that makes stories by completing the query provided by the user Once a upon time in Sri Lanka there was a boy named... when you get a query you will complete the story\n",
      "\n",
      "User: Once upon a time in Sri Lanka there was a boy named...\n",
      "\n",
      "AI: Once upon a time in Sri Lanka, there was a boy named Rohan. Rohan was known throughout the small village of Kandy for his curiosity and adventurous spirit. One day, while exploring the dense forest behind his family's tea plantation, he stumbled upon a hidden entrance to a cave. With a flicker of excitement in his eyes, he stepped inside, unafraid of the dark.\n"
     ]
    }
   ],
   "source": [
    "response = conv_chain.invoke(\"Once a upon time in Sri Lanka\")\n",
    "\n",
    "print(response['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
